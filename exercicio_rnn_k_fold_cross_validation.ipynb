{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercicio-rnn-k-fold-cross-validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulaLuana/deep-learning-exercises/blob/master/exercicio_rnn_k_fold_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJZ34vjykZQy"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjvsfX5wkZQ3"
      },
      "source": [
        "# Fundamentals of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_Ze8Z1BkZQ4"
      },
      "source": [
        "## Generalization: The goal of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypNLqqC-kZQ6"
      },
      "source": [
        "**Adding white-noise channels or all-zeros channels to MNIST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG8RIO6qnsov"
      },
      "source": [
        "Questão 1) Na célula abaixo, a variável **train_images_with_zeros_channels** representa um dataset gerado a partir das imagens inciais, com um canal de cor completamente zero. Complete o código da célula abaixo para que a variável **train_images_with_noise_channels**, da mesma forma que **train_images_with_zeros_channels** tenha mais um canal de cor, entretanto os valores devem ser gerados randomicamente. Essas duas variáveis representaão as imagens com atributos com alguma esécie de ruído."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOqkv5ElUSfq"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9euzEepBkZQ7"
      },
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "train_images_with_zeros_channels = np.concatenate(\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1)\n",
        "\n",
        "train_images_with_noise_channels = np.concatenate(\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qagCX91kZQ8"
      },
      "source": [
        "**Training the same model on MNIST data with noise channels or all-zero channels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOi95DvypPyZ"
      },
      "source": [
        "Questão 2) Complemente o código abaixo para definir um modelo sequencial com duas camadas totalmente conectadas. A primeira com 512 unidades com ativação ReLU, a segunda é uma camada de saída com a função Softmax para o conjunto de classes do problema em questão. Treine o modelo com as imagens com canal de cor gerado aleatoriamente utilizando  10 épocas, 20% do treino para validação e batch_size de tamanho 128."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weq38xEmZ97A"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvuADbbbafoQ",
        "outputId": "2299cdac-9607-4ab0-c59d-8be0aa252eab"
      },
      "source": [
        "np.unique(train_labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bB6mpbfkZQ9"
      },
      "source": [
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3nOQNjIcflv"
      },
      "source": [
        "train = train_images_with_noise_channels[:int(0.8 * len(train_images))]\n",
        "validation = train_images_with_noise_channels[int(0.8 * len(train_images)):]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcIdBPOLp6VN"
      },
      "source": [
        "partial_x_train = train[:,:-1]\n",
        "partial_y_train = train[:,-1]\n",
        "x_val = validation[:,:-1]\n",
        "y_val = validation[:,-1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OGXMYxlbFtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fe2ec4-411f-4e6c-d4e5-9052ae8e35fb"
      },
      "source": [
        "model = get_model()\n",
        "history_noise = model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=128, validation_data=(x_val, y_val))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 11s 27ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 7s 20ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16z_NwYwsxTi",
        "outputId": "daf3a84d-d002-4392-d1a0-9633664b0d52"
      },
      "source": [
        "partial_y_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.33929876, 0.96557781, 0.85332235, ..., 0.56977633, 0.90084945,\n",
              "       0.95906552])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhZewJkMqAOS"
      },
      "source": [
        "Questão 3) Obtenha um novo modelo e treine com os mesmos parâmetros da questão anterior utilizando as imagens com canal de cor zerado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBRUbAkWpsvs"
      },
      "source": [
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation=\"linear\"),\n",
        "        layers.Dense(64, activation=\"linear\"),\n",
        "        layers.Dense(10, activation=\"relu\"),\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vanKpXs7uyba"
      },
      "source": [
        "train = train_images_with_zeros_channels[:int(0.8 * len(train_images))]\n",
        "validation = train_images_with_zeros_channels[int(0.8 * len(train_images)):]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfO75Yrjuybb"
      },
      "source": [
        "partial_x_train = train[:,:-1]\n",
        "partial_y_train = train[:,-1]\n",
        "x_val = validation[:,:-1]\n",
        "y_val = validation[:,-1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kkOjCIAugcO",
        "outputId": "60aeab18-9dde-4ac2-b359-edd6eb0c6a0e"
      },
      "source": [
        "model = get_model()\n",
        "history_zeros = model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=128, validation_data=(x_val, y_val))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0326 - accuracy: 0.9976 - val_loss: 9.5401e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5378e-07 - accuracy: 1.0000 - val_loss: 9.5377e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5371e-07 - accuracy: 1.0000 - val_loss: 9.5373e-07 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5369e-07 - accuracy: 1.0000 - val_loss: 9.5369e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5368e-07 - accuracy: 1.0000 - val_loss: 9.5369e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5368e-07 - accuracy: 1.0000 - val_loss: 9.5369e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5368e-07 - accuracy: 1.0000 - val_loss: 9.5369e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5368e-07 - accuracy: 1.0000 - val_loss: 9.5369e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5368e-07 - accuracy: 1.0000 - val_loss: 9.5369e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.5368e-07 - accuracy: 1.0000 - val_loss: 9.5369e-07 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn4bMKL4kZQ9"
      },
      "source": [
        "**Plotting a validation accuracy comparison**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfvs8ENPqTJn"
      },
      "source": [
        "Questão 4) Plot em um único gráfico as curvas da acurácia dos modelos treinados anteriormente. Avalie o efeito dos modelos treinados com os novos canais de cor (zero e com ruído aletório)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wTh9essveQJ"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Dqcfc0kZQ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ca5d3821-2b30-4289-c53e-0b19abcc6c92"
      },
      "source": [
        "acc1 = history_noise.history[\"accuracy\"]\n",
        "acc2 = history_zeros.history[\"accuracy\"]\n",
        "epochs = range(1, len(acc1) + 1)\n",
        "plt.plot(epochs, acc1, \"b\", label=\"noise data\", color='red')\n",
        "plt.plot(epochs, acc2, \"b\", label=\"reset data\", color='green')\n",
        "plt.title(\"Curvas da acurácia dos modelos treinados anteriormente\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiVQOjwOkZQ-"
      },
      "source": [
        "**Fitting a MNIST model with randomly shuffled labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4No-tHZJW0DG"
      },
      "source": [
        "Questão 5) Altere a célula a seguir para que as labels utilizadas para treino sejam o resultado de uma permutação aleatória das labels dos dados originais. Treine o modelo e valie o resultado do treinamento utilizando essas labels. Plot os gráficos de acurácia para treino e validação. Como se comportou a acurácia nos dados de treino e de validação? O que isso nos sugere?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7SMJgmtykG_"
      },
      "source": [
        "import random as random"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXaf_IsTkZQ-"
      },
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsjrERaS1ArP",
        "outputId": "ea5e33bf-1be4-4299-d42f-74635911adfd"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvp-v4ppyNMj"
      },
      "source": [
        "random_train_labels = train_labels.copy()\n",
        "random.shuffle(random_train_labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2Zv6wh31CSp",
        "outputId": "c4c7274a-f328-41fd-8a10-834cdea85488"
      },
      "source": [
        "random_train_labels"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 0, 9, ..., 7, 5, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7rKKEaS1xiC"
      },
      "source": [
        "x_train = train_images[:int(0.8 * len(train_images))]\n",
        "x_val = train_images[int(0.8 * len(train_images)):]\n",
        "y_train = random_train_labels[:int(0.8 * len(train_images))]\n",
        "y_val = random_train_labels[int(0.8 * len(train_images)):]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfHLo3HRd4CG",
        "outputId": "68a65f67-ff49-40e9-fab3-c931d3441b17"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 1568)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuyI5S7Z0m1q"
      },
      "source": [
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation=\"linear\"),\n",
        "        layers.Dense(64, activation=\"linear\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMU7us0Z1xiF",
        "outputId": "06bcad63-2cf7-4323-ab41-2defdd06ffe3"
      },
      "source": [
        "model = get_model()\n",
        "history_labels_random = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_val, y_val))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3327 - accuracy: 0.1023 - val_loss: 2.3098 - val_accuracy: 0.1068\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3053 - accuracy: 0.1105 - val_loss: 2.3046 - val_accuracy: 0.1104\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3031 - accuracy: 0.1119 - val_loss: 2.3117 - val_accuracy: 0.1025\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3011 - accuracy: 0.1148 - val_loss: 2.3094 - val_accuracy: 0.1090\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2993 - accuracy: 0.1185 - val_loss: 2.3090 - val_accuracy: 0.1098\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2982 - accuracy: 0.1197 - val_loss: 2.3082 - val_accuracy: 0.1085\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2965 - accuracy: 0.1213 - val_loss: 2.3116 - val_accuracy: 0.1030\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2954 - accuracy: 0.1218 - val_loss: 2.3156 - val_accuracy: 0.1006\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2941 - accuracy: 0.1243 - val_loss: 2.3129 - val_accuracy: 0.1082\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2930 - accuracy: 0.1257 - val_loss: 2.3144 - val_accuracy: 0.1049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JaesQohc3GuO",
        "outputId": "5bbf3aa1-fc60-4257-e283-45652b1c1201"
      },
      "source": [
        "acc = history_labels_random.history[\"accuracy\"]\n",
        "val_acc = history_labels_random.history[\"val_accuracy\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"b\", label=\"accuracy train\", color='red')\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"val_accuracy\", color='green')\n",
        "plt.title(\"Curvas da acurácia e validação da acurácia com os labels em random\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idb7UC7TkZRC"
      },
      "source": [
        "Questão 6) Treine e valide o modelo aplicando o método k-fold cross validation para as seguintes configurações de parâmetros das camadas ocultas. \n",
        "\n",
        "\n",
        "\n",
        "*   1 camada densa com 512 unidades\n",
        "*   1 camada densa com 256 un1dades\n",
        "*   2 camadas densas uma com 512 unidades e outra com 128 unidades\n",
        "*    2 camadas densas uma com 256 unidades e outra com 128 unidades\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-caLSLTd5h4i"
      },
      "source": [
        "from sklearn.model_selection import KFold\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea-EoaTW4_Vh"
      },
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_7CdhDO5ZD7"
      },
      "source": [
        "**1 camada densa com 512 unidades**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Dly2ij4ZSu"
      },
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "kfold = KFold(n_splits=5)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMV0_5btia8S"
      },
      "source": [
        "inputs = train_images.copy()\n",
        "targets = train_labels.copy()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx9SRJJe4ZTK",
        "outputId": "c1e5a9a4-21f5-4aa9-d6dd-ff024967eec4"
      },
      "source": [
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"linear\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=\"rmsprop\",\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=300,\n",
        "              epochs=10)\n",
        "  \n",
        "\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.4501 - accuracy: 0.8662\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.3184 - accuracy: 0.9086\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3051 - accuracy: 0.9135\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2911 - accuracy: 0.9173\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2867 - accuracy: 0.9194\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2805 - accuracy: 0.9209\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2756 - accuracy: 0.9235\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2730 - accuracy: 0.9234\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2697 - accuracy: 0.9245\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2674 - accuracy: 0.9252\n",
            "Score for fold 1: loss of 0.29510870575904846; accuracy of 92.04166531562805%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 15ms/step - loss: 0.4481 - accuracy: 0.8671\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3105 - accuracy: 0.9109\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2931 - accuracy: 0.9164\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2838 - accuracy: 0.9190\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2773 - accuracy: 0.9217\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2745 - accuracy: 0.9226\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2690 - accuracy: 0.9244\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2659 - accuracy: 0.9260\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2626 - accuracy: 0.9264\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2609 - accuracy: 0.9258\n",
            "Score for fold 2: loss of 0.3286066949367523; accuracy of 90.84166884422302%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 15ms/step - loss: 0.4392 - accuracy: 0.8719\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3122 - accuracy: 0.9113\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2974 - accuracy: 0.9165\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2873 - accuracy: 0.9205\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2824 - accuracy: 0.9214\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2762 - accuracy: 0.9237\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2714 - accuracy: 0.9246\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2681 - accuracy: 0.9261\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2667 - accuracy: 0.9266\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2636 - accuracy: 0.9271\n",
            "Score for fold 3: loss of 0.3048035204410553; accuracy of 91.35833382606506%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 15ms/step - loss: 0.4372 - accuracy: 0.8712\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3081 - accuracy: 0.9124\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2895 - accuracy: 0.9190\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2799 - accuracy: 0.9211\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2735 - accuracy: 0.9237\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2691 - accuracy: 0.9255\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2662 - accuracy: 0.9259\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2631 - accuracy: 0.9264\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2599 - accuracy: 0.9284\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2571 - accuracy: 0.9287\n",
            "Score for fold 4: loss of 0.3360792398452759; accuracy of 90.88333249092102%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 15ms/step - loss: 0.4557 - accuracy: 0.8660\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3195 - accuracy: 0.9079\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3023 - accuracy: 0.9147\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.2938 - accuracy: 0.9185\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2867 - accuracy: 0.9198\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2832 - accuracy: 0.9207\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2765 - accuracy: 0.9229\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2760 - accuracy: 0.9225\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2718 - accuracy: 0.9239\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2693 - accuracy: 0.9250\n",
            "Score for fold 5: loss of 0.27728089690208435; accuracy of 92.5499975681305%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oTB8aD0lilo"
      },
      "source": [
        "**1 camada densa com 256 unidades**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0qcdSK6lilp"
      },
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "kfold = KFold(n_splits=5)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bktEHeKslilr",
        "outputId": "85cc7409-7aa9-4db3-f469-fc3560303499"
      },
      "source": [
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  model = keras.Sequential([\n",
        "        layers.Dense(256, activation=\"linear\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=\"rmsprop\",\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=300,\n",
        "              epochs=10)\n",
        "  \n",
        "\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.4524 - accuracy: 0.8708\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.3087 - accuracy: 0.9116\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2921 - accuracy: 0.9174\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2849 - accuracy: 0.9198\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2776 - accuracy: 0.9222\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2738 - accuracy: 0.9236\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2712 - accuracy: 0.9244\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2665 - accuracy: 0.9259\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2652 - accuracy: 0.9256\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2629 - accuracy: 0.9274\n",
            "Score for fold 1: loss of 0.2826490104198456; accuracy of 92.09166765213013%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.4429 - accuracy: 0.8717\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.3042 - accuracy: 0.9127\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2866 - accuracy: 0.9194\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2771 - accuracy: 0.9225\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2716 - accuracy: 0.9250\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2667 - accuracy: 0.9247\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2623 - accuracy: 0.9265\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2611 - accuracy: 0.9268\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2584 - accuracy: 0.9283\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.2558 - accuracy: 0.9291\n",
            "Score for fold 2: loss of 0.30748119950294495; accuracy of 91.95833206176758%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.4420 - accuracy: 0.8739\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.3033 - accuracy: 0.9141\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2908 - accuracy: 0.9185\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2807 - accuracy: 0.9226\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2743 - accuracy: 0.9244\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2694 - accuracy: 0.9265\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2653 - accuracy: 0.9266\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2636 - accuracy: 0.9272\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2605 - accuracy: 0.9273\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2584 - accuracy: 0.9289\n",
            "Score for fold 3: loss of 0.30136579275131226; accuracy of 91.8916642665863%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.4419 - accuracy: 0.8743\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2982 - accuracy: 0.9157\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2812 - accuracy: 0.9205\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2742 - accuracy: 0.9226\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2676 - accuracy: 0.9254\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2625 - accuracy: 0.9265\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.2592 - accuracy: 0.9267\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2565 - accuracy: 0.9287\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2552 - accuracy: 0.9290\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2522 - accuracy: 0.9306\n",
            "Score for fold 4: loss of 0.32699620723724365; accuracy of 91.52500033378601%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.4595 - accuracy: 0.8676\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.3103 - accuracy: 0.9129\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2950 - accuracy: 0.9169\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2853 - accuracy: 0.9193\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.2790 - accuracy: 0.9225\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.2766 - accuracy: 0.9230\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.2728 - accuracy: 0.9225\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2691 - accuracy: 0.9240\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.2659 - accuracy: 0.9261\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.2642 - accuracy: 0.9259\n",
            "Score for fold 5: loss of 0.27042365074157715; accuracy of 92.5083339214325%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPdyU0HImEbR"
      },
      "source": [
        "**2 camadas densas uma com 512 unidades e outra com 128 unidades**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvL67ImhmaFN"
      },
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "kfold = KFold(n_splits=5)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KHMpNYqmaFd",
        "outputId": "6e116817-1a1f-40bb-d0a3-ec12135e4d95"
      },
      "source": [
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"linear\"),\n",
        "        layers.Dense(512, activation=\"linear\"),\n",
        "        layers.Dense(128, activation=\"linear\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=\"rmsprop\",\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=300,\n",
        "              epochs=10)\n",
        "  \n",
        "\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.5306 - accuracy: 0.8440\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.4021 - accuracy: 0.8810\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3674 - accuracy: 0.8926\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3452 - accuracy: 0.9001\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3311 - accuracy: 0.9040\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3237 - accuracy: 0.9062\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.3134 - accuracy: 0.9103\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.3078 - accuracy: 0.9126\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3004 - accuracy: 0.9136\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.2965 - accuracy: 0.9157\n",
            "Score for fold 1: loss of 0.31603050231933594; accuracy of 91.04999899864197%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 5s 27ms/step - loss: 0.5538 - accuracy: 0.8394\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3926 - accuracy: 0.8860\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3623 - accuracy: 0.8938\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3425 - accuracy: 0.9001\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3268 - accuracy: 0.9044\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3139 - accuracy: 0.9086\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3071 - accuracy: 0.9120\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3023 - accuracy: 0.9139\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.2974 - accuracy: 0.9137\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.2940 - accuracy: 0.9159\n",
            "Score for fold 2: loss of 0.32921895384788513; accuracy of 91.21666550636292%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 6s 28ms/step - loss: 0.5395 - accuracy: 0.8424\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3964 - accuracy: 0.8836\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3649 - accuracy: 0.8948\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3440 - accuracy: 0.9001\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.3287 - accuracy: 0.9059\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3197 - accuracy: 0.9082\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3118 - accuracy: 0.9116\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3057 - accuracy: 0.9133\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.2988 - accuracy: 0.9154\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.2960 - accuracy: 0.9160\n",
            "Score for fold 3: loss of 0.3429185748100281; accuracy of 90.15833139419556%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.5279 - accuracy: 0.8425\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3918 - accuracy: 0.8851\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3550 - accuracy: 0.8970\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3374 - accuracy: 0.9017\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3231 - accuracy: 0.9063\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3128 - accuracy: 0.9111\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3040 - accuracy: 0.9147\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.2981 - accuracy: 0.9149\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.2929 - accuracy: 0.9169\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.2867 - accuracy: 0.9190\n",
            "Score for fold 4: loss of 0.3306466042995453; accuracy of 91.19166731834412%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.5852 - accuracy: 0.8371\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.4061 - accuracy: 0.8809\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3718 - accuracy: 0.8914\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.3516 - accuracy: 0.8977\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 5s 32ms/step - loss: 0.3355 - accuracy: 0.9036\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3234 - accuracy: 0.9066\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3162 - accuracy: 0.9107\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3118 - accuracy: 0.9118\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3055 - accuracy: 0.9133\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.2982 - accuracy: 0.9147\n",
            "Score for fold 5: loss of 0.28773701190948486; accuracy of 92.07500219345093%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmnwq7iGmwa5"
      },
      "source": [
        "**2 camadas densas uma com 256 unidades e outra com 128 unidades**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrkRArgHnDx8"
      },
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "kfold = KFold(n_splits=5)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E2JB7ofnDx-",
        "outputId": "73407100-232d-4836-ce0b-b3edb562dee4"
      },
      "source": [
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  model = keras.Sequential([\n",
        "        layers.Dense(256, activation=\"linear\"),\n",
        "        layers.Dense(256, activation=\"linear\"),\n",
        "        layers.Dense(128, activation=\"linear\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=\"rmsprop\",\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=300,\n",
        "              epochs=10)\n",
        "  \n",
        "\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 14ms/step - loss: 0.4852 - accuracy: 0.8547\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3596 - accuracy: 0.8943\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3391 - accuracy: 0.9023\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3269 - accuracy: 0.9051\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3179 - accuracy: 0.9087\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3087 - accuracy: 0.9107\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3026 - accuracy: 0.9126\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2982 - accuracy: 0.9146\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.2948 - accuracy: 0.9158\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2901 - accuracy: 0.9174\n",
            "Score for fold 1: loss of 0.2849912941455841; accuracy of 92.00000166893005%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 14ms/step - loss: 0.4763 - accuracy: 0.8579\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3539 - accuracy: 0.8983\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3348 - accuracy: 0.9029\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3204 - accuracy: 0.9069\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3097 - accuracy: 0.9102\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3052 - accuracy: 0.9103\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2959 - accuracy: 0.9157\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2922 - accuracy: 0.9158\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2883 - accuracy: 0.9168\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2832 - accuracy: 0.9191\n",
            "Score for fold 2: loss of 0.3517643213272095; accuracy of 90.48333168029785%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 14ms/step - loss: 0.4922 - accuracy: 0.8567\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3572 - accuracy: 0.8969\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3354 - accuracy: 0.9024\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3224 - accuracy: 0.9075\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3137 - accuracy: 0.9104\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3052 - accuracy: 0.9137\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2995 - accuracy: 0.9168\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2965 - accuracy: 0.9157\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2892 - accuracy: 0.9184\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2853 - accuracy: 0.9191\n",
            "Score for fold 3: loss of 0.3207944929599762; accuracy of 90.9833312034607%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 14ms/step - loss: 0.4691 - accuracy: 0.8580\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3487 - accuracy: 0.8989\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3266 - accuracy: 0.9067\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3153 - accuracy: 0.9092\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3065 - accuracy: 0.9135\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3002 - accuracy: 0.9141\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2941 - accuracy: 0.9173\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2867 - accuracy: 0.9186\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2840 - accuracy: 0.9204\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2808 - accuracy: 0.9187\n",
            "Score for fold 4: loss of 0.33326154947280884; accuracy of 90.9916639328003%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.4914 - accuracy: 0.8536\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3628 - accuracy: 0.8940\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3425 - accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3267 - accuracy: 0.9058\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3159 - accuracy: 0.9087\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3106 - accuracy: 0.9107\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.3065 - accuracy: 0.9122\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3009 - accuracy: 0.9146\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2955 - accuracy: 0.9158\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.2921 - accuracy: 0.9172\n",
            "Score for fold 5: loss of 0.28338906168937683; accuracy of 92.5249993801117%\n"
          ]
        }
      ]
    }
  ]
}